{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98d5d388",
   "metadata": {},
   "source": [
    "# NLP Pipelines Demos\n",
    "\n",
    "This notebook shows a few demos to help understand the nlp pipelines package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "446c4d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (1.7.1)\n",
      "Requirement already satisfied: nltk in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (3.9.1)\n",
      "Requirement already satisfied: spacy in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (3.8.7)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (2.2.6)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (2.3.1)\n",
      "Requirement already satisfied: fasttext in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (0.9.3)\n",
      "Requirement already satisfied: sentence_transformers in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (5.0.0)\n",
      "Requirement already satisfied: rank_bm25 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (0.2.2)\n",
      "Requirement already satisfied: keybert in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (0.9.0)\n",
      "Requirement already satisfied: multi_rake in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (0.0.2)\n",
      "Requirement already satisfied: yake in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (0.6.0)\n",
      "Requirement already satisfied: torch in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (2.7.1)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (3.5)\n",
      "Requirement already satisfied: xgboost in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (3.0.2)\n",
      "Requirement already satisfied: transformers in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (4.54.1)\n",
      "Requirement already satisfied: hdbscan in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (0.8.40)\n",
      "Requirement already satisfied: umap in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (0.1.1)\n",
      "Requirement already satisfied: pyarrow in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (21.0.0)\n",
      "Requirement already satisfied: bertopic in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 21)) (0.17.3)\n",
      "Requirement already satisfied: umap-learn in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (0.5.9.post2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 1)) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 1)) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from scikit-learn->-r requirements.txt (line 1)) (3.6.0)\n",
      "Requirement already satisfied: click in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from nltk->-r requirements.txt (line 2)) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from nltk->-r requirements.txt (line 2)) (2025.7.29)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from nltk->-r requirements.txt (line 2)) (4.67.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 3)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 3)) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 3)) (1.0.13)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 3)) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 3)) (3.0.10)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 3)) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 3)) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 3)) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 3)) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 3)) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 3)) (0.16.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 3)) (2.32.4)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 3)) (2.11.7)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 3)) (3.0.3)\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 3)) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from spacy->-r requirements.txt (line 3)) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 5)) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from pandas->-r requirements.txt (line 5)) (2025.2)\n",
      "Requirement already satisfied: pybind11>=2.2 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from fasttext->-r requirements.txt (line 6)) (3.0.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (0.34.3)\n",
      "Requirement already satisfied: Pillow in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from sentence_transformers->-r requirements.txt (line 7)) (4.14.1)\n",
      "Requirement already satisfied: rich>=10.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from keybert->-r requirements.txt (line 11)) (14.0.0)\n",
      "Requirement already satisfied: pycld2>=0.41 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from multi_rake->-r requirements.txt (line 12)) (0.42)\n",
      "Requirement already satisfied: pyrsistent>=0.14.2 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from multi_rake->-r requirements.txt (line 12)) (0.20.0)\n",
      "Requirement already satisfied: jellyfish in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from yake->-r requirements.txt (line 13)) (1.2.0)\n",
      "Requirement already satisfied: segtok in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from yake->-r requirements.txt (line 13)) (1.5.11)\n",
      "Requirement already satisfied: tabulate in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from yake->-r requirements.txt (line 13)) (0.9.0)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from torch->-r requirements.txt (line 14)) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from torch->-r requirements.txt (line 14)) (1.14.0)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from torch->-r requirements.txt (line 14)) (2025.7.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 17)) (6.0.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 17)) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from transformers->-r requirements.txt (line 17)) (0.5.3)\n",
      "Requirement already satisfied: plotly>=4.7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from bertopic->-r requirements.txt (line 21)) (6.2.0)\n",
      "Requirement already satisfied: llvmlite>0.36.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from bertopic->-r requirements.txt (line 21)) (0.44.0)\n",
      "Requirement already satisfied: numba>=0.51.2 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from umap-learn->-r requirements.txt (line 22)) (0.61.2)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from umap-learn->-r requirements.txt (line 22)) (0.5.13)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers->-r requirements.txt (line 7)) (1.1.5)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from plotly>=4.7.0->bertopic->-r requirements.txt (line 21)) (2.0.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 3)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 3)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 3)) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 5)) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 3)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 3)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 3)) (2025.7.14)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from rich>=10.4.0->keybert->-r requirements.txt (line 11)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from rich>=10.4.0->keybert->-r requirements.txt (line 11)) (2.19.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 14)) (1.3.0)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 3)) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 3)) (0.1.5)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy->-r requirements.txt (line 3)) (1.5.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 3)) (0.21.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 3)) (7.3.0.post1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from jinja2->spacy->-r requirements.txt (line 3)) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->-r requirements.txt (line 3)) (1.2.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert->-r requirements.txt (line 11)) (0.1.2)\n",
      "Requirement already satisfied: wrapt in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->-r requirements.txt (line 3)) (1.17.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (3.10.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from matplotlib) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: numpy>=1.23 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install dependencies\n",
    "%pip install -r requirements.txt \n",
    "\n",
    "# required for the demo\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d535248e",
   "metadata": {},
   "source": [
    "## Example: Simple Data, Clustered\n",
    "\n",
    "For perhaps the simplest example, let's take a small toy dataset/corpus and make clusters. First we'll use methods individually, then we'll use the pipeline object to help simplify.\n",
    "\n",
    "### Using Specific Methods\n",
    "\n",
    "You can use any of the methods directly. For example, we can clean text or use a bag of words vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4480a2b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rbirmin/Documents/nlp_pipelines/nlp_pipelines/dataset/Dataset.py:132: SyntaxWarning: invalid escape sequence '\\R'\n",
      "  repr_str += \"\\Results: \"\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dataset with 8 texts\n",
      "Texts: ['The new stethoscope model by Littmann is available now.', 'Philips unveils an innovative heart monitor with improved accuracy.']... +6 more>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nlp_pipelines.vectorizer import BagOfWords\n",
    "from nlp_pipelines.dataset import Dataset\n",
    "from nlp_pipelines import preprocess\n",
    "\n",
    "# First, a simple dataset for demonstration\n",
    "texts = [\n",
    "    \"The new stethoscope model by Littmann is available now.\",\n",
    "    \"Philips unveils an innovative heart monitor with improved accuracy.\",\n",
    "    \"Medtronic announces a breakthrough in robotic surgery technology.\",\n",
    "    \"GE Healthcare's ultrasound device provides high-definition imaging.\",\n",
    "    \"Stryker introduces a new orthopedic surgical tool.\",\n",
    "    \"Johnson & Johnson releases a new line of surgical instruments.\",\n",
    "    \"Siemens Healthineers develops a state-of-the-art MRI scanner.\",\n",
    "    \"Boston Scientific launches a catheter designed for heart surgery.\"\n",
    "]\n",
    "dataset = Dataset(texts)\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "471d67dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new stethoscope model Littmann available', 'Philips unveils innovative heart monitor improved accuracy', 'Medtronic announces breakthrough robotic surgery technology', 'GE Healthcare ultrasound device provides high definition imaging', 'Stryker introduces new orthopedic surgical tool', 'Johnson Johnson releases new line surgical instruments', 'Siemens Healthineers develops state art MRI scanner', 'Boston Scientific launches catheter designed heart surgery']\n"
     ]
    }
   ],
   "source": [
    "# let's remove stopwords (uninformative words)\n",
    "stopword_remover = preprocess.StopwordRemove()\n",
    "\n",
    "dataset = stopword_remover.transform(dataset)\n",
    "print(dataset.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2dec76d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['new stethoscope model Littmann available', 'philip unveil innovative heart monitor improved accuracy', 'medtronic announce breakthrough robotic surgery technology', 'GE Healthcare ultrasound device provide high definition imaging', 'stryker introduce new orthopedic surgical tool', 'Johnson Johnson release new line surgical instrument', 'Siemens Healthineers develop state art MRI scanner', 'Boston Scientific launch catheter design heart surgery']\n"
     ]
    }
   ],
   "source": [
    "# let's lemmatize to see what that does too\n",
    "\n",
    "lemmatizer = preprocess.Lemmatize()\n",
    "\n",
    "dataset = lemmatizer.transform(dataset)\n",
    "print(dataset.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172c0ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dataset with 8 texts, vectors: 47-dim\n",
      "Texts: ['new stethoscope model Littmann available', 'philip unveil innovative heart monitor improved accuracy']... +6 more>\n",
      "[[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      "  0 0 0 0 1 0 1 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 1 0 0 0 0 0 1 0 0 0 1 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      "  0 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 0 0 0 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# ok, maybe this is reasonable to vectorize?\n",
    "\n",
    "vectorizer = BagOfWords()\n",
    "\n",
    "vectorizer.fit(dataset)\n",
    "dataset = vectorizer.transform(dataset) # for now, the same dataset since it's all we have\n",
    "\n",
    "print(dataset) # show us the state of the dataset\n",
    "print(dataset.vectors) # show us just the vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1b64187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dataset with 8 texts, vectors: 47-dim, results: 8 items\n",
      "Texts: ['new stethoscope model Littmann available', 'philip unveil innovative heart monitor improved accuracy']... +6 more\\Results: [1 1]... +6 more>\n",
      "[1 1 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# to make this end to end, let's try to cluster to see what that gets us\n",
    "from nlp_pipelines.clusterer import Kmeans\n",
    "\n",
    "model = Kmeans(num_clusters=2, random_state=101)\n",
    "\n",
    "model.fit(dataset)\n",
    "dataset = model.predict(dataset)\n",
    "\n",
    "print(dataset) # what's in the dataset now\n",
    "print(dataset.results) # what are the results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8fae77",
   "metadata": {},
   "source": [
    "### Using a pipeline\n",
    "\n",
    "Instead of doing these one by one, a helper class \"Pipeline\" lets us define these as a pipeline and run them all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59fd867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: [1 1 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from nlp_pipelines.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    {\"name\": \"preproc1\", \"method\": \"preprocess.StopwordRemove\"},\n",
    "    {\"name\": \"preproc2\", \"method\": \"preprocess.Lemmatize\"},\n",
    "    {\"name\": \"vectorize\", \"method\": \"vectorizer.BagOfWords\"},\n",
    "    {\"name\": \"cluster\", \"method\": \"clusterer.Kmeans\", \"params\":{\"num_clusters\":2, \"random_state\": 101}}\n",
    "])\n",
    "pipeline.set_data(train_data=dataset, run_data=dataset) # for now, train and run on the same data\n",
    "pipeline.run()\n",
    "\n",
    "print(\"Results:\", pipeline.run_data.results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc37670",
   "metadata": {},
   "source": [
    "Same results, since it's the same pipeline.\n",
    "\n",
    "Also, the intermediate results are still part of the pipeline's dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5648071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original texts: ['The new stethoscope model by Littmann is available now.', 'Philips unveils an innovative heart monitor with improved accuracy.', 'Medtronic announces a breakthrough in robotic surgery technology.', \"GE Healthcare's ultrasound device provides high-definition imaging.\", 'Stryker introduces a new orthopedic surgical tool.', 'Johnson & Johnson releases a new line of surgical instruments.', 'Siemens Healthineers develops a state-of-the-art MRI scanner.', 'Boston Scientific launches a catheter designed for heart surgery.']\n",
      "Preprocessed texts: ['new stethoscope model Littmann available', 'philip unveil innovative heart monitor improved accuracy', 'medtronic announce breakthrough robotic surgery technology', 'GE Healthcare ultrasound device provide high definition imaging', 'stryker introduce new orthopedic surgical tool', 'Johnson Johnson release new line surgical instrument', 'Siemens Healthineers develop state art MRI scanner', 'Boston scientific launch catheter design heart surgery']\n",
      "Vectors: [[0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 0\n",
      "  0 0 0 1 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
      "  0 0 0 0 0 1 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0\n",
      "  0 0 0 0 1 0 1 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 2 0 1 0 0 0 0 0 1 0 0 0 1 0 0\n",
      "  0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1\n",
      "  0 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  1 0 0 0 0 1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# the dataset keeps the last of the other things it's seen\n",
    "\n",
    "# original text\n",
    "print(\"Original texts:\", pipeline.run_data.original_texts)\n",
    "# preprocessed text\n",
    "print(\"Preprocessed texts:\", pipeline.run_data.texts)\n",
    "# vectors\n",
    "print(\"Vectors:\", pipeline.run_data.vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b4caa2",
   "metadata": {},
   "source": [
    "## Example: Simple Data, Classified\n",
    "\n",
    "Now, let's pick a dataset with truths and use that to classify the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa601e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dataset with 5 texts\n",
      "Texts: ['I love this movie', 'This is terrible']... +3 more\n",
      "Truths: ['positive', 'negative']... +3 more>\n",
      "<Dataset with 3 texts\n",
      "Texts: ['I love this movie', 'This is terrible']... +1 more\n",
      "Truths: ['positive', 'negative']... +1 more> <Dataset with 2 texts\n",
      "Texts: ['Awful experience', 'It was okay']\n",
      "Truths: ['negative', 'neutral']>\n"
     ]
    }
   ],
   "source": [
    "texts = [\"I love this movie\", \"This is terrible\", \"Fantastic work\", \"Awful experience\", \"It was okay\"]\n",
    "truths = [\"positive\", \"negative\", \"positive\", \"negative\", \"neutral\"]\n",
    "dataset = Dataset(texts, truths)\n",
    "\n",
    "print(dataset)\n",
    "\n",
    "train, test = dataset.split(count=3, labeled=True)\n",
    "print(train, test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f36f0b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: ['positive' 'positive']\n",
      "Truths: ['negative', 'neutral']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# the words are quite different, so low co-occurence is going to break tfidf/bow; let's try to embed with a sentence embedding to get context!\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    {\"name\": \"vectorize\", \"method\": \"vectorizer.SentenceEmbedding\"},\n",
    "    {\"name\": \"classify\", \"method\": \"classifier.Xgboost\"}\n",
    "])\n",
    "\n",
    "\n",
    "pipeline.set_data(train_data=train, run_data=test) # now we have different train and test data!\n",
    "pipeline.run()\n",
    "\n",
    "print(\"Results:\", pipeline.run_data.results)\n",
    "print(\"Truths:\", pipeline.run_data.truths) # TODO evaluation code was not finished for all result types as of the writing of this.\n",
    "\n",
    "# I ran it without a seed, and got 1/2 right, so maybe three sentences isn't enough to train a tree model ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3212e047",
   "metadata": {},
   "source": [
    "## Example: Simple Data, Labeled\n",
    "\n",
    "Finally, we have labeling (formerly \"keyword extraction\"); retuning 0 to n labels.\n",
    "However, we have two different kinds of labelers: extractive ones pick important words from the document. Predictive ones take the list of labels and try to predict which apply to text.\n",
    "\n",
    "In any case, let's start with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59fda05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Dataset with 5 texts\n",
      "Texts: ['Patient shows symptoms of fever and cough, possible pneumonia diagnosis.', 'Headache and nausea reported, likely migraine.']... +3 more\n",
      "Truths: [['pneumonia', 'respiratory infection'], ['migraine']]... +3 more>\n"
     ]
    }
   ],
   "source": [
    "# common dataset\n",
    "texts = [\n",
    "    \"Patient shows symptoms of fever and cough, possible pneumonia diagnosis.\",\n",
    "    \"Headache and nausea reported, likely migraine.\",\n",
    "    \"Frequent urination and fatigue, potential diabetes condition.\",\n",
    "    \"Coughing and shortness of breath, indicative of respiratory infection.\",\n",
    "    \"Reports of dizziness, nausea, and blurred vision, possible stroke.\"\n",
    "]\n",
    "\n",
    "truths = [\n",
    "    [\"pneumonia\", \"respiratory infection\"],\n",
    "    [\"migraine\"],\n",
    "    [\"diabetes\"],\n",
    "    [\"respiratory infection\"],\n",
    "    [\"stroke\"]\n",
    "]\n",
    "\n",
    "possible_labels = [\"pneumonia\", \"migraine\", \"diabetes\", \"respiratory infection\", \"stroke\"]\n",
    "\n",
    "# Create the Dataset object\n",
    "dataset = Dataset(texts, truths)\n",
    "\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6441c1d8",
   "metadata": {},
   "source": [
    "### Extractive Labeling\n",
    "What are the top 2 words according to an extractive labeler? Let's clean a little bit then try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abbb3aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: [['patient show symptom', 'patient show'], ['Headache and nausea', 'nausea report'], ['potential diabetes condition', 'frequent urination'], ['cough and shortness', 'shortness of breath'], ['report of dizziness', 'nausea']]\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    {\"name\": \"preprocess\", \"method\": \"preprocess.Lemmatize\"},\n",
    "    {\"name\": \"extract\", \"method\": \"labeler.Yake\", \"params\":{\"top_k\":2}}\n",
    "])\n",
    "\n",
    "\n",
    "pipeline.set_data(train_data=dataset, run_data=dataset)\n",
    "pipeline.run()\n",
    "\n",
    "print(\"Results:\", pipeline.run_data.results) # not sure how to best evaluate extractive keywords in our context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d924858",
   "metadata": {},
   "source": [
    "## Predictive labeling\n",
    "Let's use a method to predict which keywords from our list seem to best apply. We'll need to embed more things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d499ef0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: [['pneumonia', 'respiratory infection', 'migraine', 'diabetes', 'stroke'], ['migraine', 'stroke', 'pneumonia', 'diabetes', 'respiratory infection']]\n",
      "Truths: None\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    {\"name\": \"vectorize\", \"method\": \"vectorizer.SentenceEmbedding\"},\n",
    "    {\"name\": \"predict\", \"method\": \"labeler.ThresholdSim\"}\n",
    "])\n",
    "\n",
    "pipeline.set_data(train_data=train, run_data=test, possible_labels=possible_labels)\n",
    "pipeline.run()\n",
    "\n",
    "print(\"Results:\", pipeline.run_data.results) # TODO! it only SORTS the keywords on distance right now! Do the threshold.\n",
    "print(\"Truths:\", pipeline.run_data.truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee358103",
   "metadata": {},
   "source": [
    "## Real Data Demos\n",
    "\n",
    "Let's load some real data (`./demo_data`)\n",
    "\n",
    "`sample_5_newsgroup_text.parquet` contains text posted in 5 newsgroups, with labels; adapted from [SetFit/20_newsgroups](https://huggingface.co/datasets/SetFit/20_newsgroups).\n",
    "\n",
    "`springer-127-parsed.json` contains abstracts and keywords from the journal [Social Psychiatry and Psychiatric Epidemiology](https://link.springer.com/journal/127)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f3330f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = Dataset.from_parquet(\"./demo_data/sample_5_newsgroup_text.parquet\", text_field=\"text\", truth_field=\"label_text\")\n",
    "\n",
    "abstracts = Dataset.from_json(\"./demo_data/springer-127-parsed.json\", text_field=\"abstract\", truth_field=\"keywords\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163a8c4f",
   "metadata": {},
   "source": [
    "### Clustering both\n",
    "\n",
    "We can test a few more of the clustering methods on this real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fae2e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Dataset with 500 texts, vectors: 11869-dim, results: 500 items\n",
       "Texts: [\"it' a fair stretch of anyone' imagin to expect them to attach ani credibl to anyth written in time magazin in the past twenti years, i'd imagine. the enquir at least get the name attach to the right bodi parts. =mark --\", 'so, how did you guy *learn* this? is it someth you were born with, or did you make horribl grind nois the first few times? (how mani times?) i would think you\\'d have to have a certain amount of \"feel\" for it to begin with. some peopl would never get it, and other (like me) would never have the gut to tri it, unless mayb you were plan to buy a new transmiss anyway... (btw, i\\'v heard that quit a few trucker and race car driver shift thi way).']... +498 more\n",
       "Truths: ['talk.politics.guns', 'rec.autos']... +498 more\\Results: [-1  1]... +498 more>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups_pipeline = Pipeline([\n",
    "    {\"name\": \"preproc1\", \"method\": \"preprocess.Stem\"},\n",
    "    {\"name\": \"vectorize\", \"method\": \"vectorizer.Tfidf\"},\n",
    "    {\"name\": \"cluster\", \"method\": \"clusterer.Svm\"}\n",
    "])\n",
    "\n",
    "newsgroups_pipeline.set_data(newsgroups, newsgroups)\n",
    "newsgroups_pipeline.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45ea518d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  2722\n",
      "Number of labels: 0\n",
      "Progress: 100.0% words/sec/thread:  103954 lr:  0.000000 avg.loss:  2.603551 ETA:   0h 0m 0s\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:328: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/spade/lib/python3.12/site-packages/sklearn/manifold/_spectral_embedding.py:328: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Dataset with 500 texts, vectors: 100-dim, results: 500 items\n",
       "Texts: ['Purpose Disparities mental health sexual orientation groups young adults long discussed aim cross sectional study investigate moderating effects sexual orientation associations social factors depressive symptoms suicidal ideation young adults Methods study included participants aged 18–25y French EpiCov cohort outcome variables depressive symptoms suicidal ideation Poisson regressions robust error variance performed investigate associations social factors outcomes according sexual orientation lesbian gay bisexual defining according sexuality sexual minority SM heterosexual wishing answer belonging SM NSM Results prevalence depressive symptoms suicidal ideation higher SM NSM group depressive symptoms significant moderating effects sexual orientation observed female vs male sex NSM adjusted Prevalence Ratio aPR 1.58[1.28–1.95 SM aPR 1.03[0.78–1.36 age category 22–25y vs 21y NSM aPR 1.32[1.05–1.67 SM aPR 0.78[0.59–1.03 suicidal ideation significant moderating effect observed vs relationship NSM aPR 1.55[1.14–2.12 SM aPR 0.82[0.59–1.13 Conclusion study conducted known social risk factors mental problems explain higher prevalence depressive symptoms suicidal ideation young SM group studies needed understand specific challenges faced young people', 'Background Sleep duration physical activity associated internalizing problems genetic confounding measurement error introduce bias assessed genetic confounding associations modifiable lifestyle internalizing problems device based questionnaire assessments estimate shared genetic risk different assessments adolescents Methods preregistered study Adolescents Brain Cognitive Development cohort included European adolescents self reported device based sleep duration N = moderate vigorous physical activity MVPA days week N = Brief Problem Monitor assess self reported internalizing problem scores Genetic sensitivity analyses conducted assess genetic confounding combining polygenic scores molecular based heritability internalizing problems Results Longer sleep duration associated lower internalizing problems self reported SD SE = SD objective SD SE = SD assessments frequent MVPA associated lower internalizing problems self reported SD SE = SD device based SD SE = SD assessments Substantial genetic confounding found self reported sleep duration internalizing problems predominantly boys clear evidence genetic confounding found associations device based sleep duration measures MVPA internalizing problems Conclusion observed negative relationship reported child sleep duration internalizing problems partly genetic confounding particularly boys genetic influence likely captured reporting measurement error shared method variance impact adolescent sleep duration internalizing problems overestimated self reports especially boys associations physical activity genetically confounded']... +498 more\n",
       "Truths: [['Depressive symptoms', 'Epidemiology', 'Sexual orientation', 'Social factors', 'Suicidal ideation', 'Young adults'], ['Genetic confounding', 'Modifiable lifestyle', 'Shared method variance', 'Adolescent internalizing problems']]... +498 more\\Results: [1 1]... +498 more>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and similar for the abstracts\n",
    "\n",
    "abstracts_pipeline = Pipeline([\n",
    "    {\"name\": \"preproc1\", \"method\": \"preprocess.TokenFilter\", \"params\":{\"remove_if\":[\"is_stop\", \"is_punct\", \"is_space\", \"like_num\", \"like_url\", \"like_email\"]}},\n",
    "    {\"name\": \"vectorize\", \"method\": \"vectorizer.FastText\"},\n",
    "    {\"name\": \"cluster\", \"method\": \"clusterer.GraphAffinity\", \"args\":{\"num_clusters\": 2}}\n",
    "])\n",
    "\n",
    "abstracts_pipeline.set_data(abstracts, abstracts)\n",
    "abstracts_pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f538a120",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Let's classify our newsgroup data. Also, let's pretend we train on train, save the pipeline, then use the trained pipeline \"later\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfa74640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rec.autos', 'sci.space', 'comp.sys.mac.hardware',\n",
       "       'comp.sys.mac.hardware', 'sci.space', 'comp.sys.mac.hardware',\n",
       "       'sci.space', 'comp.sys.mac.hardware', 'talk.politics.guns',\n",
       "       'talk.politics.guns', 'talk.politics.guns', 'sci.space',\n",
       "       'talk.politics.guns', 'rec.autos', 'comp.sys.mac.hardware',\n",
       "       'comp.sys.mac.hardware', 'rec.autos', 'sci.space', 'comp.graphics',\n",
       "       'sci.space', 'talk.politics.guns', 'rec.autos',\n",
       "       'talk.politics.guns', 'talk.politics.guns', 'sci.space',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware', 'comp.graphics',\n",
       "       'comp.graphics', 'comp.graphics', 'rec.autos',\n",
       "       'comp.sys.mac.hardware', 'comp.graphics', 'comp.sys.mac.hardware',\n",
       "       'talk.politics.guns', 'comp.sys.mac.hardware', 'sci.space',\n",
       "       'comp.graphics', 'comp.graphics', 'rec.autos', 'sci.space',\n",
       "       'comp.sys.mac.hardware', 'rec.autos', 'comp.sys.mac.hardware',\n",
       "       'comp.graphics', 'comp.graphics', 'comp.graphics',\n",
       "       'talk.politics.guns', 'talk.politics.guns',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware', 'comp.graphics',\n",
       "       'sci.space', 'rec.autos', 'comp.sys.mac.hardware',\n",
       "       'comp.sys.mac.hardware', 'sci.space', 'comp.sys.mac.hardware',\n",
       "       'comp.graphics', 'comp.sys.mac.hardware', 'comp.sys.mac.hardware',\n",
       "       'sci.space', 'comp.sys.mac.hardware', 'comp.graphics',\n",
       "       'talk.politics.guns', 'sci.space', 'comp.graphics', 'sci.space',\n",
       "       'rec.autos', 'comp.sys.mac.hardware', 'comp.sys.mac.hardware',\n",
       "       'sci.space', 'comp.graphics', 'comp.sys.mac.hardware',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware',\n",
       "       'comp.sys.mac.hardware', 'sci.space', 'comp.sys.mac.hardware',\n",
       "       'sci.space', 'rec.autos', 'sci.space', 'talk.politics.guns',\n",
       "       'comp.graphics', 'comp.graphics', 'sci.space', 'sci.space',\n",
       "       'comp.sys.mac.hardware', 'talk.politics.guns',\n",
       "       'comp.sys.mac.hardware', 'talk.politics.guns',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware', 'comp.graphics',\n",
       "       'comp.sys.mac.hardware', 'talk.politics.guns',\n",
       "       'talk.politics.guns', 'sci.space', 'talk.politics.guns',\n",
       "       'sci.space', 'talk.politics.guns', 'talk.politics.guns',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware',\n",
       "       'talk.politics.guns', 'rec.autos', 'sci.space',\n",
       "       'talk.politics.guns', 'comp.graphics', 'rec.autos',\n",
       "       'comp.sys.mac.hardware', 'talk.politics.guns', 'sci.space',\n",
       "       'sci.space', 'sci.space', 'talk.politics.guns', 'sci.space',\n",
       "       'sci.space', 'talk.politics.guns', 'rec.autos', 'comp.graphics',\n",
       "       'comp.graphics', 'comp.graphics', 'comp.sys.mac.hardware',\n",
       "       'talk.politics.guns', 'sci.space', 'comp.sys.mac.hardware',\n",
       "       'talk.politics.guns', 'talk.politics.guns', 'talk.politics.guns',\n",
       "       'talk.politics.guns', 'comp.graphics', 'talk.politics.guns',\n",
       "       'comp.graphics', 'talk.politics.guns', 'sci.space',\n",
       "       'comp.sys.mac.hardware', 'comp.graphics', 'comp.sys.mac.hardware',\n",
       "       'sci.space', 'sci.space', 'talk.politics.guns',\n",
       "       'comp.sys.mac.hardware', 'sci.space', 'comp.graphics',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware', 'sci.space',\n",
       "       'comp.sys.mac.hardware', 'rec.autos', 'comp.sys.mac.hardware',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware', 'comp.graphics',\n",
       "       'comp.graphics', 'talk.politics.guns', 'comp.graphics',\n",
       "       'sci.space', 'comp.sys.mac.hardware', 'sci.space',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware', 'comp.graphics',\n",
       "       'talk.politics.guns', 'talk.politics.guns', 'sci.space',\n",
       "       'comp.graphics', 'rec.autos', 'rec.autos', 'comp.sys.mac.hardware',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware',\n",
       "       'comp.sys.mac.hardware', 'talk.politics.guns', 'comp.graphics',\n",
       "       'comp.sys.mac.hardware', 'sci.space', 'comp.sys.mac.hardware',\n",
       "       'comp.graphics', 'comp.sys.mac.hardware', 'rec.autos', 'sci.space',\n",
       "       'comp.sys.mac.hardware', 'rec.autos', 'sci.space',\n",
       "       'talk.politics.guns', 'talk.politics.guns', 'rec.autos',\n",
       "       'rec.autos', 'sci.space', 'sci.space', 'talk.politics.guns',\n",
       "       'rec.autos', 'sci.space', 'rec.autos', 'sci.space',\n",
       "       'comp.graphics', 'comp.sys.mac.hardware', 'comp.graphics',\n",
       "       'talk.politics.guns', 'comp.sys.mac.hardware',\n",
       "       'comp.sys.mac.hardware', 'talk.politics.guns', 'rec.autos',\n",
       "       'comp.graphics', 'rec.autos', 'comp.sys.mac.hardware', 'sci.space',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware', 'rec.autos',\n",
       "       'talk.politics.guns', 'comp.sys.mac.hardware',\n",
       "       'talk.politics.guns', 'rec.autos', 'comp.sys.mac.hardware',\n",
       "       'talk.politics.guns', 'comp.graphics', 'rec.autos', 'rec.autos',\n",
       "       'comp.sys.mac.hardware', 'talk.politics.guns',\n",
       "       'talk.politics.guns', 'talk.politics.guns',\n",
       "       'comp.sys.mac.hardware', 'sci.space', 'talk.politics.guns',\n",
       "       'comp.sys.mac.hardware', 'sci.space', 'comp.graphics',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware', 'sci.space',\n",
       "       'comp.sys.mac.hardware', 'talk.politics.guns', 'sci.space',\n",
       "       'talk.politics.guns', 'comp.graphics', 'comp.sys.mac.hardware',\n",
       "       'sci.space', 'sci.space', 'sci.space', 'sci.space', 'sci.space',\n",
       "       'rec.autos', 'sci.space', 'sci.space', 'comp.sys.mac.hardware',\n",
       "       'comp.sys.mac.hardware', 'rec.autos', 'rec.autos',\n",
       "       'talk.politics.guns', 'sci.space', 'comp.sys.mac.hardware',\n",
       "       'comp.sys.mac.hardware', 'sci.space', 'comp.sys.mac.hardware',\n",
       "       'sci.space', 'comp.sys.mac.hardware', 'sci.space',\n",
       "       'comp.sys.mac.hardware', 'talk.politics.guns', 'sci.space',\n",
       "       'sci.space', 'talk.politics.guns', 'comp.sys.mac.hardware',\n",
       "       'rec.autos', 'talk.politics.guns', 'rec.autos',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware', 'sci.space',\n",
       "       'comp.sys.mac.hardware', 'sci.space', 'comp.graphics',\n",
       "       'talk.politics.guns', 'rec.autos', 'comp.sys.mac.hardware',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware',\n",
       "       'talk.politics.guns', 'sci.space', 'talk.politics.guns',\n",
       "       'comp.sys.mac.hardware', 'sci.space', 'talk.politics.guns',\n",
       "       'comp.graphics', 'comp.sys.mac.hardware', 'comp.sys.mac.hardware',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware',\n",
       "       'talk.politics.guns', 'sci.space', 'rec.autos',\n",
       "       'comp.sys.mac.hardware', 'rec.autos', 'comp.sys.mac.hardware',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware', 'sci.space',\n",
       "       'talk.politics.guns', 'sci.space', 'comp.graphics', 'rec.autos',\n",
       "       'talk.politics.guns', 'talk.politics.guns',\n",
       "       'comp.sys.mac.hardware', 'rec.autos', 'sci.space',\n",
       "       'comp.sys.mac.hardware', 'talk.politics.guns',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware',\n",
       "       'talk.politics.guns', 'comp.graphics', 'talk.politics.guns',\n",
       "       'rec.autos', 'comp.sys.mac.hardware', 'rec.autos', 'sci.space',\n",
       "       'rec.autos', 'sci.space', 'sci.space', 'comp.graphics',\n",
       "       'sci.space', 'sci.space', 'sci.space', 'comp.graphics',\n",
       "       'talk.politics.guns', 'comp.sys.mac.hardware',\n",
       "       'comp.sys.mac.hardware', 'comp.sys.mac.hardware', 'comp.graphics',\n",
       "       'rec.autos', 'sci.space', 'comp.sys.mac.hardware', 'comp.graphics',\n",
       "       'talk.politics.guns', 'sci.space', 'talk.politics.guns',\n",
       "       'talk.politics.guns', 'talk.politics.guns', 'talk.politics.guns',\n",
       "       'talk.politics.guns', 'comp.graphics', 'rec.autos', 'sci.space',\n",
       "       'talk.politics.guns', 'comp.sys.mac.hardware', 'sci.space',\n",
       "       'sci.space', 'talk.politics.guns', 'comp.graphics',\n",
       "       'comp.sys.mac.hardware', 'rec.autos', 'comp.sys.mac.hardware',\n",
       "       'rec.autos', 'comp.sys.mac.hardware', 'talk.politics.guns',\n",
       "       'sci.space', 'rec.autos', 'comp.graphics', 'sci.space',\n",
       "       'talk.politics.guns', 'comp.sys.mac.hardware',\n",
       "       'talk.politics.guns', 'comp.sys.mac.hardware',\n",
       "       'talk.politics.guns', 'comp.sys.mac.hardware',\n",
       "       'talk.politics.guns', 'sci.space', 'sci.space', 'sci.space',\n",
       "       'comp.sys.mac.hardware', 'talk.politics.guns',\n",
       "       'talk.politics.guns', 'rec.autos', 'talk.politics.guns',\n",
       "       'sci.space', 'talk.politics.guns', 'talk.politics.guns',\n",
       "       'sci.space', 'talk.politics.guns', 'rec.autos',\n",
       "       'talk.politics.guns', 'sci.space', 'comp.sys.mac.hardware',\n",
       "       'talk.politics.guns', 'rec.autos', 'comp.graphics',\n",
       "       'comp.graphics', 'rec.autos', 'comp.sys.mac.hardware', 'sci.space',\n",
       "       'comp.sys.mac.hardware', 'sci.space', 'talk.politics.guns',\n",
       "       'comp.sys.mac.hardware'], dtype='<U21')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups = Dataset.from_parquet(\"./demo_data/sample_5_newsgroup_text.parquet\", text_field=\"text\", truth_field=\"label_text\")\n",
    "\n",
    "train, test = newsgroups.split(ratio=0.2, labeled=True, splitLabeled=True)\n",
    "\n",
    "newsgroups_pipeline = Pipeline([\n",
    "    {\"name\": \"preproc1\", \"method\": \"preprocess.TokenFilter\", \"params\":{\"remove_if\":[\"is_stop\", \"is_punct\", \"is_space\", \"like_num\", \"like_url\", \"like_email\"]}},\n",
    "    {\"name\": \"vectorize\", \"method\": \"vectorizer.SentenceEmbedding\"},\n",
    "    {\"name\": \"cluster\", \"method\": \"classifier.LabelProp\"}\n",
    "])\n",
    "\n",
    "newsgroups_pipeline.set_data(train_data=train)\n",
    "newsgroups_pipeline.train()\n",
    "\n",
    "newsgroups_pipeline.save(\"./demo_data/newsgroups_demo.pickle\")\n",
    "\n",
    "loaded_pipeline = Pipeline.load(\"./demo_data/newsgroups_demo.pickle\")\n",
    "loaded_pipeline.set_data(run_data=test)\n",
    "loaded_pipeline.predict()\n",
    "\n",
    "loaded_pipeline.run_data.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e771d90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.725,\n",
       " 'precision_macro': 0.7551116530528296,\n",
       " 'recall_macro': 0.7253627615876612,\n",
       " 'f1_macro': 0.7209393897428795}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nlp_pipelines.evaluate import evaluate\n",
    "\n",
    "evaluate(loaded_pipeline.run_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
