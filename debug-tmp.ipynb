{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddde70bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_pipelines.dataset import Dataset\n",
    "from nlp_pipelines.pipeline import Pipeline\n",
    "import copy\n",
    "from nlp_pipelines.evaluate import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389504f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the abstracts are in a json file, which is a usual web serialization\n",
    "abstracts = Dataset.from_json(\"./demo_data/springer-127-parsed.json\", text_field=\"abstract\", truth_field=\"keywords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bd74eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 true keywords\n",
    "possible_labels = [\"mental health\", \"depression\", \"schizophrenia\",\n",
    " \"covid-19\", \"suicide\", \"anxiety\", \"loneliness\",\n",
    " \"psychosis\", \"epidemiology\", \"mental disorders\"]\n",
    "\n",
    "# keep only keywords in this list, in a derived dataset from abstracts\n",
    "\n",
    "abstracts_labels = copy.deepcopy(abstracts)\n",
    "\n",
    "abstracts_labels.truths = [[item.lower() for item in sublist if item.lower() in possible_labels] for sublist in abstracts_labels.truths]\n",
    "\n",
    "# test and train split, remove ones with now empty keyword lists too!\n",
    "train, test = abstracts_labels.split(ratio=0.8, seed=101, labeled=True, splitLabeled=True)\n",
    "\n",
    "print(train)\n",
    "print(test)\n",
    "\n",
    "train_3 = copy.deepcopy(train)\n",
    "test_3 = copy.deepcopy(test)\n",
    "train_4 = copy.deepcopy(train)\n",
    "test_4 = copy.deepcopy(test)\n",
    "\n",
    "# logistic regression pipeline\n",
    "\n",
    "logistic_pipeline = Pipeline([\n",
    "    {\"name\": \"lemmatize\", \"method\":\"preprocess.Lemmatize\"},\n",
    "    {\"name\": \"vectorize\", \"method\":\"vectorizer.SentenceEmbedding\", \"params\":{\"model_name\":'all-MiniLM-L6-v2'}},\n",
    "    {\"name\": \"logistic\", \"method\": \"labeler.MultiLogistic\"}\n",
    "])\n",
    "\n",
    "logistic_pipeline.set_data(train_data=train_3, run_data=test_3, possible_labels=possible_labels)\n",
    "\n",
    "nn_pipeline = Pipeline([\n",
    "    {\"name\": \"lemmatize\", \"method\":\"preprocess.Lemmatize\"},\n",
    "    {\"name\": \"vectorize\", \"method\":\"vectorizer.SentenceEmbedding\", \"params\":{\"model_name\":'all-MiniLM-L6-v2'}},\n",
    "    {\"name\": \"logistic\", \"method\": \"labeler.SimpleNNLabeler\", \"params\":{\"threshold\": 0.2}}\n",
    "])\n",
    "\n",
    "nn_pipeline.set_data(train_data=train_4, run_data=test_4, possible_labels=possible_labels)\n",
    "\n",
    "logistic_pipeline.run()\n",
    "nn_pipeline.run()\n",
    "\n",
    "print(\"Logistic Regression Results\")\n",
    "print(evaluate(logistic_pipeline.run_data))\n",
    "\n",
    "print(\"Neural Net Results\")\n",
    "print(evaluate(nn_pipeline.run_data))\n",
    "\n",
    "print(nn_pipeline.run_data.results[0:3])\n",
    "print(nn_pipeline.run_data.truths[0:3])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
